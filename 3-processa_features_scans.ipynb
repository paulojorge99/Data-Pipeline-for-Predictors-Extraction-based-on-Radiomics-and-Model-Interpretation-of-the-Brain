{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n"
     ]
    }
   ],
   "source": [
    "def subids(file):\n",
    "    file_subid=pd.read_csv(file)\n",
    "    lista=[]\n",
    "    count=0\n",
    "    for x in range(len(file_subid['paciente'])):\n",
    "        ids=file_subid['paciente'][x]\n",
    "        if ids not in lista:\n",
    "            lista.append(ids)\n",
    "            count+=1\n",
    "    return lista\n",
    "\n",
    "lista=subids(\"0-DS1_metascans.csv\")\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    lista[i].replace(\"''\",\"\")\n",
    "print(len(lista))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 2004)\n"
     ]
    }
   ],
   "source": [
    "#see all the radiomics features\n",
    "def feature_analysis(file):\n",
    "    radiomics_features=pd.read_csv(file)\n",
    "    #radiomics_features.isna().values.sum()\n",
    "    #radiomics_features=radiomics_features.dropna()\n",
    "    cols = radiomics_features.columns\n",
    "    #print(radiomics_features.select_dtypes(include=['category']).columns.tolist())\n",
    "    #print(radiomics_features.select_dtypes(exclude=['category']).columns.tolist())\n",
    "    #num_cols = radiomics_features._get_numeric_data().columns\n",
    "    #print(list(set(cols) - set(num_cols)))\n",
    "    #columns_to_drop = ['diagnostics_Image-original_Minimum','diagnostics_Image-original_Mean','diagnostics_Image-original_Maximum']\n",
    "    #radiomics_features = radiomics_features.drop(columns_to_drop, axis = 1)\n",
    "    #print(num_cols)\n",
    "    print(radiomics_features.shape)\n",
    "    return radiomics_features\n",
    "\n",
    "file=\"A.all_features_scans.csv\"\n",
    "radiomics_features=feature_analysis(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 2004)\n",
      "(852, 2004)\n"
     ]
    }
   ],
   "source": [
    "#drop the columns of all features that aren't numeric\n",
    "def drop_columns(radiomics_features):\n",
    "    my_type = 'float64'\n",
    "\n",
    "    dtypes = radiomics_features.dtypes.to_dict()\n",
    "    \n",
    "    for col_nam, typ in dtypes.items():\n",
    "\n",
    "         if (typ != my_type) and col_nam != \"ID\":\n",
    "                #print(col_nam)\n",
    "                radiomics_features.drop(col_nam, axis = 1,inplace = True)\n",
    "                \n",
    "    #radiomics_features.drop(\"diagnostics_Image-original_Mean\", axis = 1,inplace = True)\n",
    "    #radiomics_features.drop(\"diagnostics_Image-original_Maximum\", axis = 1,inplace = True)\n",
    "    print(radiomics_features.shape)\n",
    "    return radiomics_features\n",
    "cleaned_features=drop_columns(radiomics_features)\n",
    "\n",
    "#get a csv file with all the numeric radiomics features\n",
    "dtypes = cleaned_features.dtypes.to_dict()\n",
    "for col_nam, typ in dtypes.items():\n",
    "        count=0\n",
    "        num = cleaned_features[col_nam][0]\n",
    "        for x in range(1,len(cleaned_features[col_nam])):\n",
    "            if cleaned_features[col_nam][x]!=num:\n",
    "                count+=1\n",
    "        \n",
    "        if count==0:\n",
    "            cleaned_features.drop(col_nam, axis = 1,inplace = True)\n",
    "        \n",
    "        \n",
    "print(cleaned_features.shape)\n",
    "   \n",
    "cleaned_features.to_csv(\"A.all_features_scans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 2008)\n"
     ]
    }
   ],
   "source": [
    "ficheiro = pd.read_csv(\"A.all_features_scans.csv\")\n",
    "ficheiroUmaLinha = pd.read_csv(\"0-DS1_metascans.csv\")\n",
    "ages = []\n",
    "mmse = []\n",
    "cdr  = []\n",
    "sex  = []\n",
    "for index, row in ficheiroUmaLinha.iterrows():\n",
    "    for colunaDois in ficheiro.columns:\n",
    "        ages.append(row[\"idade_0\"])\n",
    "        ages.append(row[\"idade_24\"])\n",
    "        mmse.append(row[\"MMSE_0\"])\n",
    "        mmse.append(row[\"MMSE_24\"])\n",
    "        cdr.append(row[\"CDR_0\"])\n",
    "        cdr.append(row[\"CDR_24\"])\n",
    "        if row[\"sexo\"]==\"F\":\n",
    "            sex.append(0)\n",
    "            sex.append(0)\n",
    "        else:\n",
    "            sex.append(1)\n",
    "            sex.append(1)\n",
    "        break\n",
    "        \n",
    "ficheiro[\"AGE\"] = ages\n",
    "ficheiro[\"MMSE\"] = mmse\n",
    "ficheiro[\"CDR\"] = cdr\n",
    "ficheiro[\"SEX\"] = sex\n",
    "\n",
    "print(ficheiro.shape)\n",
    "\n",
    "ficheiro.to_csv(\"A1.cleaned_features_scans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificacao(MMSE,CDR):\n",
    "        \n",
    "    if MMSE > 24 and MMSE <=30 and CDR == 0.0:\n",
    "        return \"CN\"\n",
    "        \n",
    "    if MMSE > 24 and MMSE <=30 and CDR == 0.5:\n",
    "        return \"MCI\"\n",
    "    \n",
    "    if MMSE > 1 and MMSE <=24 and CDR == 0.5:\n",
    "         return \"AD\"\n",
    "        \n",
    "    if MMSE > 1 and MMSE <=30 and CDR > 0.5:\n",
    "        return \"AD\"\n",
    "    \n",
    "    else:\n",
    "        return null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 2009)\n"
     ]
    }
   ],
   "source": [
    "ficheiro = pd.read_csv(\"A1.cleaned_features_scans.csv\")\n",
    "\n",
    "pacientes = {}\n",
    "paciente = \"\"\n",
    "estadoAnterior = \"\"\n",
    "for index, row in ficheiro.iterrows():\n",
    "    mmse = row[\"MMSE\"]\n",
    "    cdr = row[\"CDR\"]\n",
    "    paciente_atual = row[\"ID\"].split(\"/\")[1][5:15]\n",
    "    if paciente == paciente_atual:\n",
    "        est = classificacao(mmse, cdr)\n",
    "        estadoAnterior = estadoAnterior + \"-\" + est\n",
    "        pacientes[paciente_atual] = estadoAnterior\n",
    "    else:\n",
    "        estadoAnterior = classificacao(mmse, cdr)\n",
    "        paciente = paciente_atual\n",
    "        \n",
    "status =[]\n",
    "for index, row in ficheiro.iterrows():\n",
    "    paciente_atual = row[\"ID\"].split(\"/\")[1][5:15]\n",
    "    status.append(pacientes[paciente_atual])\n",
    "\n",
    "ficheiro[\"Transition\"] = status\n",
    "\n",
    "print(ficheiro.shape)\n",
    "\n",
    "ficheiro.to_csv(\"A1.cleaned_features_scans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(812, 2010)\n"
     ]
    }
   ],
   "source": [
    "#labeling\n",
    "\n",
    "ficheiro = pd.read_csv(\"A1.cleaned_features_scans.csv\")\n",
    "\n",
    "classes = [\"CN-MCI\", \"CN-AD\", \"MCI-AD\", \"CN-CN\", \"MCI-MCI\", \"AD-AD\"]\n",
    "classes_ids = {\"CN-MCI\":0, \"CN-AD\":1, \"MCI-AD\":2, \"CN-CN\":3, \"MCI-MCI\":4, \"AD-AD\":5}\n",
    "Transition_ID = []\n",
    "\n",
    "for index, row in ficheiro.iterrows():\n",
    "    if row[\"Transition\"] not in classes:\n",
    "        ficheiro.drop(index, inplace=True)\n",
    "    else:\n",
    "        Transition_ID.append(classes_ids[row[\"Transition\"]])\n",
    "\n",
    "ficheiro[\"Transition_ID\"] = Transition_ID\n",
    "\n",
    "print(ficheiro.shape)\n",
    "\n",
    "ficheiro.to_csv(\"A1.cleaned_features_scans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 2010)\n"
     ]
    }
   ],
   "source": [
    "#DELETE MONTH 24 IN THE WHOLE DATASET\n",
    "\n",
    "ficheiro = pd.read_csv(\"A1.cleaned_features_scans.csv\")\n",
    "\n",
    "df = ficheiro.drop_duplicates(subset='ID', keep='first')\n",
    "    \n",
    "print(df.shape)\n",
    "df.to_csv(\"A1.cleaned_features_scans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 2011)\n"
     ]
    }
   ],
   "source": [
    "#COLUMN CLASS\n",
    "\n",
    "ficheiro = pd.read_csv(\"A1.cleaned_features_scans.csv\")\n",
    "\n",
    "classe_lista = []\n",
    "transit = list(ficheiro[\"Transition\"])\n",
    "\n",
    "for i in transit:\n",
    "    a=i.split(\"-\")\n",
    "    classe_lista.append(a[0])\n",
    "\n",
    "ficheiro[\"Class\"] = classe_lista\n",
    "\n",
    "print(ficheiro.shape)\n",
    "\n",
    "ficheiro.to_csv(\"A1.cleaned_features_scans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 2012)\n"
     ]
    }
   ],
   "source": [
    "#COLUMN CLASS_ID\n",
    "\n",
    "ficheiro = pd.read_csv(\"A1.cleaned_features_scans.csv\")\n",
    "\n",
    "classes = [\"CN\", \"MCI\",\"AD\"]\n",
    "classes_ids = {\"CN\":0, \"MCI\":1, \"AD\":2}\n",
    "Class_ID = []\n",
    "\n",
    "for index, row in ficheiro.iterrows():\n",
    "    if row[\"Class\"] not in classes:\n",
    "        ficheiro.drop(index, inplace=True)\n",
    "    else:\n",
    "        Class_ID.append(classes_ids[row[\"Class\"]])\n",
    "\n",
    "ficheiro[\"Class_ID\"] = Class_ID\n",
    "\n",
    "print(ficheiro.shape)\n",
    "\n",
    "ficheiro.to_csv(\"A1.cleaned_features_scans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CN-MCI': 16,\n",
       " 'CN-AD': 1,\n",
       " 'MCI-AD': 88,\n",
       " 'CN-CN': 125,\n",
       " 'MCI-MCI': 101,\n",
       " 'AD-AD': 75}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contagens_transicoes(ficheiro):\n",
    "    contas = {\"CN-MCI\":0, \"CN-AD\":0, \"MCI-AD\":0, \"CN-CN\":0, \"MCI-MCI\":0, \"AD-AD\":0}\n",
    "    for index, row in ficheiro.iterrows():\n",
    "        contas[row[\"Transition\"]] += 1\n",
    "    return contas\n",
    "\n",
    "contagens_transicoes(pd.read_csv(\"A1.cleaned_features_scans.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CN': 142, 'MCI': 189, 'AD': 75}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contagens_classes(ficheiro):\n",
    "    contas = {\"CN\":0, \"MCI\":0, \"AD\":0}\n",
    "    for index, row in ficheiro.iterrows():\n",
    "        contas[row[\"Class\"]] += 1\n",
    "    return contas\n",
    "\n",
    "contagens_classes(pd.read_csv(\"A1.cleaned_features_scans.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  EXTRA-PROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(812, 2010)\n"
     ]
    }
   ],
   "source": [
    "# PUT THE ID CORRECTLY - ONLY WITH THE PATIENT NUMBER\n",
    "\n",
    "ficheiroBase = pd.read_csv(\"A1.cleaned_features_scans.csv\")\n",
    "\n",
    "for index, row in ficheiroBase.iterrows():\n",
    "    idBase=row[0]\n",
    "    idBase=str(idBase).split(\"/\")[1]\n",
    "    idBaseF=idBase.split(\"_\")[1]+\"_\"+idBase.split(\"_\")[2]+\"_\"+idBase.split(\"_\")[3]\n",
    "\n",
    "    ficheiroBase[\"ID\"].replace(row[0], idBaseF, inplace = True)\n",
    "    \n",
    "print(ficheiroBase.shape)\n",
    "\n",
    "ficheiroBase.to_csv(\"A1.cleaned_features_scans.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406, 2012)\n"
     ]
    }
   ],
   "source": [
    "#normalize the data\n",
    "\n",
    "file = \"A1.cleaned_features_scans.csv\"\n",
    "\n",
    "csv = pd.read_csv(file)\n",
    "\n",
    "columns=[\"ID\",\"SEX\",\"AGE\",\"MMSE\",\"CDR\",\"Transition\",\"Transition_ID\",\"Class\",\"Class_ID\"]\n",
    "\n",
    "def normalize_radiomic():\n",
    "    \n",
    "    ficheiro = pd.read_csv(file)\n",
    "    data = ficheiro.drop(columns=columns)\n",
    "    data_normalized = data.apply(lambda x:( (x - x.min()) / (x.max()-x.min())))\n",
    "    return data_normalized\n",
    "   \n",
    "df=normalize_radiomic()\n",
    "\n",
    "listaID=csv[\"ID\"]\n",
    "listaSex=csv[\"SEX\"]\n",
    "listaAge=csv[\"AGE\"]\n",
    "listaMMSE=csv[\"MMSE\"]\n",
    "listaCDR=csv[\"CDR\"]\n",
    "listaTransitions=csv[\"Transition\"]\n",
    "listaTransitionsID=csv[\"Transition_ID\"]\n",
    "listaClasses=csv[\"Class\"]\n",
    "listaClassesID=csv[\"Class_ID\"]\n",
    "\n",
    "df.insert(0, 'ID', listaID)\n",
    "df.insert(1, 'Sex', listaSex)\n",
    "df.insert(2, 'Age', listaAge)\n",
    "df.insert(3, 'MMSE', listaMMSE)\n",
    "df.insert(4, 'CDR', listaCDR)\n",
    "df.insert(5, 'Transition_Label', listaTransitionsID)\n",
    "df.insert(6, 'Transition', listaTransitions)\n",
    "df.insert(7, 'Class_Label', listaClassesID)\n",
    "df.insert(8, 'Class', listaClasses)\n",
    "\n",
    "print(df.shape)    \n",
    "df.to_csv(\"A2.features_final_scans_normalized.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS-PROCESSING (remove labels that do not exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CN-MCI': 16,\n",
       " 'CN-AD': 1,\n",
       " 'MCI-AD': 88,\n",
       " 'CN-CN': 125,\n",
       " 'MCI-MCI': 101,\n",
       " 'AD-AD': 75}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contagens_transicoes(ficheiro):\n",
    "    contas = {\"CN-MCI\":0, \"CN-AD\":0, \"MCI-AD\":0, \"CN-CN\":0, \"MCI-MCI\":0, \"AD-AD\":0}\n",
    "    for index, row in ficheiro.iterrows():\n",
    "        contas[row[\"Transition\"]] += 1\n",
    "    return contas\n",
    "\n",
    "contagens_transicoes(pd.read_csv(\"A2.features_final_scans_normalized.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 2013)\n"
     ]
    }
   ],
   "source": [
    "#Since there is only 1 CN-AD case, it will be removed.\n",
    "\n",
    "ficheiro = pd.read_csv(\"A2.features_final_scans_normalized.csv\")\n",
    "\n",
    "classes = [\"CN-MCI\", \"MCI-AD\", \"CN-CN\", \"MCI-MCI\", \"AD-AD\"]\n",
    "classes_ids = {\"CN-MCI\":0, \"MCI-AD\":1, \"CN-CN\":2, \"MCI-MCI\":3, \"AD-AD\":4}\n",
    "Transition_ID = []\n",
    "\n",
    "for index, row in ficheiro.iterrows():\n",
    "    if row[\"Transition\"] not in classes:\n",
    "        ficheiro.drop(index, inplace=True)\n",
    "    else:\n",
    "        Transition_ID.append(classes_ids[row[\"Transition\"]])\n",
    "\n",
    "ficheiro[\"Transition_Label\"] = Transition_ID\n",
    "\n",
    "print(ficheiro.shape)\n",
    "\n",
    "ficheiro.to_csv(\"A3.DS_Brain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"A3.DS_Brain.csv\")\n",
    "#df[\"Transition_Label\"].value_counts()\n",
    "\n",
    "df[\"Transition_Label\"].replace(2,1, inplace = True)\n",
    "df[\"Transition_Label\"].replace(3,2, inplace = True)\n",
    "df[\"Transition_Label\"].replace(4,3, inplace = True)\n",
    "df[\"Transition_Label\"].replace(5,4, inplace = True)\n",
    "\n",
    "df[\"Transition_Label\"].value_counts()\n",
    "\n",
    "df.to_csv(\"A3.DS_Brain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CN-MCI': 16,\n",
       " 'CN-AD': 0,\n",
       " 'MCI-AD': 88,\n",
       " 'CN-CN': 125,\n",
       " 'MCI-MCI': 101,\n",
       " 'AD-AD': 75}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contagens_transicoes(ficheiro):\n",
    "    contas = {\"CN-MCI\":0, \"CN-AD\":0, \"MCI-AD\":0, \"CN-CN\":0, \"MCI-MCI\":0, \"AD-AD\":0}\n",
    "    for index, row in ficheiro.iterrows():\n",
    "        contas[row[\"Transition\"]] += 1\n",
    "    return contas\n",
    "\n",
    "contagens_transicoes(pd.read_csv(\"A3.DS_Brain.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405, 2013)\n",
      "(405, 2012)\n"
     ]
    }
   ],
   "source": [
    "# DELETE EXTRA COLUMN\n",
    "\n",
    "df=pd.read_csv(\"A3.DS_Brain.csv\")\n",
    "print(df.shape)\n",
    "df.drop(\"Transition_ID\",axis=1,inplace=True)\n",
    "print(df.shape)\n",
    "df.to_csv(\"A3.DS_Brain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
